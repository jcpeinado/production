{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are we doing?\n",
    "\n",
    "## Objectives \n",
    "\n",
    "\n",
    "* Build a data pipeline that downloads price data from the internet, stores it locally, transforms it into return data, and stores the feature set.\n",
    "    - Getting the data.\n",
    "    - Schemas and index in dask.\n",
    "\n",
    "* Explore the parquet format.\n",
    "    - Reading and writing parquet files.\n",
    "    - Read datasets that are stored in distributed files.\n",
    "    - Discuss dask vs pandas as a small example of big vs small data.\n",
    "    \n",
    "* Discuss the use of environment variables for settings.\n",
    "* Discuss how to use Jupyter notebooks and source code concurrently. \n",
    "* Logging and using a standard logger.\n",
    "\n",
    "## About the Data\n",
    "\n",
    "+ We will download the prices for a list of stocks.\n",
    "+ The source is Yahoo Finance and we will use the API provided by the library yfinance.\n",
    "\n",
    "\n",
    "## Medallion Architecture\n",
    "\n",
    "+ The architecture that we are thinking about is called Medallion by [DataBricks](https://www.databricks.com/glossary/medallion-architecture). It is an ELT type of thinking, although our data is well-structured.\n",
    "\n",
    "![Medallion Architecture (DataBicks)](./images/02_medallion_architecture.png)\n",
    "\n",
    "+ In our case, we would like to optimize the number of times that we download data from the internet. \n",
    "+ Ultimately, we will build a pipeline manager class that will help us control the process of obtaining and transforming our data.\n",
    "\n",
    "![](./images/02_target_pipeline_manager.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data from Yahoo Finance\n",
    "\n",
    "Yahoo Finance provides information about public stocks in different markets. The library yfinance gives us access to a fair bit of the data in Yahoo Finance. \n",
    "\n",
    "These steps are based on the instructions in:\n",
    "\n",
    "+ [yfinance documentation](https://pypi.org/project/yfinance/)\n",
    "+ [Tutorial in geeksforgeeks.org](https://www.geeksforgeeks.org/get-financial-data-from-yahoo-finance-with-python/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ If required, install: `python -m pip install yfinance`.\n",
    "+ To download the price history of a stock, first use the following setup:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getenv('SRC_DIR'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to notice in the code chunk above:\n",
    "\n",
    "+ Libraries are ordered from high-level to low-level libraries from the package manager (pip in this case, but could be conda, poetry, etc.)\n",
    "+ The command `sys.path.append(\"../05_src/)` will add the `../05_src/` directory to the path in the Notebook's kernel. This way, we can use our modules as part of the notebook.\n",
    "+ Local modules are imported at the end. \n",
    "+ The function `get_logger()` is called with `__name__` as recommended by the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to download the historical price data for a stock, we could use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-02 00:00:00+00:00</th>\n",
       "      <td>17.175100</td>\n",
       "      <td>19.686787</td>\n",
       "      <td>20.154642</td>\n",
       "      <td>19.672144</td>\n",
       "      <td>19.928572</td>\n",
       "      <td>472544800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-03 00:00:00+00:00</th>\n",
       "      <td>17.645266</td>\n",
       "      <td>20.225714</td>\n",
       "      <td>20.227858</td>\n",
       "      <td>19.917143</td>\n",
       "      <td>19.939285</td>\n",
       "      <td>450968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-04 00:00:00+00:00</th>\n",
       "      <td>17.604134</td>\n",
       "      <td>20.178572</td>\n",
       "      <td>20.328215</td>\n",
       "      <td>20.029285</td>\n",
       "      <td>20.196428</td>\n",
       "      <td>377809600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-05 00:00:00+00:00</th>\n",
       "      <td>17.694496</td>\n",
       "      <td>20.282143</td>\n",
       "      <td>20.540714</td>\n",
       "      <td>20.228930</td>\n",
       "      <td>20.451786</td>\n",
       "      <td>447580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-06 00:00:00+00:00</th>\n",
       "      <td>17.448973</td>\n",
       "      <td>20.000713</td>\n",
       "      <td>20.241072</td>\n",
       "      <td>19.984644</td>\n",
       "      <td>20.206785</td>\n",
       "      <td>344352400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-25 00:00:00+00:00</th>\n",
       "      <td>193.223404</td>\n",
       "      <td>194.169998</td>\n",
       "      <td>196.270004</td>\n",
       "      <td>193.110001</td>\n",
       "      <td>195.220001</td>\n",
       "      <td>54822100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26 00:00:00+00:00</th>\n",
       "      <td>191.481918</td>\n",
       "      <td>192.419998</td>\n",
       "      <td>194.759995</td>\n",
       "      <td>191.940002</td>\n",
       "      <td>194.270004</td>\n",
       "      <td>44594000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29 00:00:00+00:00</th>\n",
       "      <td>190.795303</td>\n",
       "      <td>191.729996</td>\n",
       "      <td>192.199997</td>\n",
       "      <td>189.580002</td>\n",
       "      <td>192.009995</td>\n",
       "      <td>47145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30 00:00:00+00:00</th>\n",
       "      <td>187.123260</td>\n",
       "      <td>188.039993</td>\n",
       "      <td>191.800003</td>\n",
       "      <td>187.470001</td>\n",
       "      <td>190.940002</td>\n",
       "      <td>55859400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-31 00:00:00+00:00</th>\n",
       "      <td>183.501022</td>\n",
       "      <td>184.399994</td>\n",
       "      <td>187.100006</td>\n",
       "      <td>184.350006</td>\n",
       "      <td>187.039993</td>\n",
       "      <td>55467800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2558 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                       Adj Close       Close        High         Low  \\\n",
       "Ticker                           AAPL        AAPL        AAPL        AAPL   \n",
       "Date                                                                        \n",
       "2013-12-02 00:00:00+00:00   17.175100   19.686787   20.154642   19.672144   \n",
       "2013-12-03 00:00:00+00:00   17.645266   20.225714   20.227858   19.917143   \n",
       "2013-12-04 00:00:00+00:00   17.604134   20.178572   20.328215   20.029285   \n",
       "2013-12-05 00:00:00+00:00   17.694496   20.282143   20.540714   20.228930   \n",
       "2013-12-06 00:00:00+00:00   17.448973   20.000713   20.241072   19.984644   \n",
       "...                               ...         ...         ...         ...   \n",
       "2024-01-25 00:00:00+00:00  193.223404  194.169998  196.270004  193.110001   \n",
       "2024-01-26 00:00:00+00:00  191.481918  192.419998  194.759995  191.940002   \n",
       "2024-01-29 00:00:00+00:00  190.795303  191.729996  192.199997  189.580002   \n",
       "2024-01-30 00:00:00+00:00  187.123260  188.039993  191.800003  187.470001   \n",
       "2024-01-31 00:00:00+00:00  183.501022  184.399994  187.100006  184.350006   \n",
       "\n",
       "Price                            Open     Volume  \n",
       "Ticker                           AAPL       AAPL  \n",
       "Date                                              \n",
       "2013-12-02 00:00:00+00:00   19.928572  472544800  \n",
       "2013-12-03 00:00:00+00:00   19.939285  450968000  \n",
       "2013-12-04 00:00:00+00:00   20.196428  377809600  \n",
       "2013-12-05 00:00:00+00:00   20.451786  447580000  \n",
       "2013-12-06 00:00:00+00:00   20.206785  344352400  \n",
       "...                               ...        ...  \n",
       "2024-01-25 00:00:00+00:00  195.220001   54822100  \n",
       "2024-01-26 00:00:00+00:00  194.270004   44594000  \n",
       "2024-01-29 00:00:00+00:00  192.009995   47145600  \n",
       "2024-01-30 00:00:00+00:00  190.940002   55859400  \n",
       "2024-01-31 00:00:00+00:00  187.039993   55467800  \n",
       "\n",
       "[2558 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px = yf.download('AAPL', start = \"2013-12-01\", end = \"2024-02-01\")\n",
    "px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-02 00:00:00+00:00</th>\n",
       "      <td>243.850006</td>\n",
       "      <td>243.850006</td>\n",
       "      <td>249.100006</td>\n",
       "      <td>241.820007</td>\n",
       "      <td>248.929993</td>\n",
       "      <td>55740700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-03 00:00:00+00:00</th>\n",
       "      <td>243.360001</td>\n",
       "      <td>243.360001</td>\n",
       "      <td>244.179993</td>\n",
       "      <td>241.889999</td>\n",
       "      <td>243.360001</td>\n",
       "      <td>40244100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-06 00:00:00+00:00</th>\n",
       "      <td>245.000000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>247.330002</td>\n",
       "      <td>243.199997</td>\n",
       "      <td>244.309998</td>\n",
       "      <td>45045600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-07 00:00:00+00:00</th>\n",
       "      <td>242.210007</td>\n",
       "      <td>242.210007</td>\n",
       "      <td>245.550003</td>\n",
       "      <td>241.350006</td>\n",
       "      <td>242.979996</td>\n",
       "      <td>40856000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-08 00:00:00+00:00</th>\n",
       "      <td>242.699997</td>\n",
       "      <td>242.699997</td>\n",
       "      <td>243.710007</td>\n",
       "      <td>240.050003</td>\n",
       "      <td>241.919998</td>\n",
       "      <td>37628900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-10 00:00:00+00:00</th>\n",
       "      <td>236.850006</td>\n",
       "      <td>236.850006</td>\n",
       "      <td>240.160004</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>240.009995</td>\n",
       "      <td>61710900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-13 00:00:00+00:00</th>\n",
       "      <td>234.399994</td>\n",
       "      <td>234.399994</td>\n",
       "      <td>234.669998</td>\n",
       "      <td>229.720001</td>\n",
       "      <td>233.529999</td>\n",
       "      <td>49630700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-14 00:00:00+00:00</th>\n",
       "      <td>233.279999</td>\n",
       "      <td>233.279999</td>\n",
       "      <td>236.119995</td>\n",
       "      <td>232.470001</td>\n",
       "      <td>234.750000</td>\n",
       "      <td>39435300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-15 00:00:00+00:00</th>\n",
       "      <td>237.869995</td>\n",
       "      <td>237.869995</td>\n",
       "      <td>238.960007</td>\n",
       "      <td>234.429993</td>\n",
       "      <td>234.639999</td>\n",
       "      <td>39832000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-16 00:00:00+00:00</th>\n",
       "      <td>228.259995</td>\n",
       "      <td>228.259995</td>\n",
       "      <td>238.009995</td>\n",
       "      <td>228.029999</td>\n",
       "      <td>237.350006</td>\n",
       "      <td>71759100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-17 00:00:00+00:00</th>\n",
       "      <td>229.979996</td>\n",
       "      <td>229.979996</td>\n",
       "      <td>232.289993</td>\n",
       "      <td>228.479996</td>\n",
       "      <td>232.119995</td>\n",
       "      <td>68488300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-21 00:00:00+00:00</th>\n",
       "      <td>222.639999</td>\n",
       "      <td>222.639999</td>\n",
       "      <td>224.419998</td>\n",
       "      <td>219.380005</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>98070400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-22 00:00:00+00:00</th>\n",
       "      <td>223.830002</td>\n",
       "      <td>223.830002</td>\n",
       "      <td>224.119995</td>\n",
       "      <td>219.789993</td>\n",
       "      <td>219.789993</td>\n",
       "      <td>64126500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-23 00:00:00+00:00</th>\n",
       "      <td>223.660004</td>\n",
       "      <td>223.660004</td>\n",
       "      <td>227.029999</td>\n",
       "      <td>222.300003</td>\n",
       "      <td>224.740005</td>\n",
       "      <td>60234800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-24 00:00:00+00:00</th>\n",
       "      <td>222.779999</td>\n",
       "      <td>222.779999</td>\n",
       "      <td>225.630005</td>\n",
       "      <td>221.410004</td>\n",
       "      <td>224.779999</td>\n",
       "      <td>54697900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-27 00:00:00+00:00</th>\n",
       "      <td>229.860001</td>\n",
       "      <td>229.860001</td>\n",
       "      <td>232.149994</td>\n",
       "      <td>223.979996</td>\n",
       "      <td>224.020004</td>\n",
       "      <td>94863400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-28 00:00:00+00:00</th>\n",
       "      <td>238.259995</td>\n",
       "      <td>238.259995</td>\n",
       "      <td>240.190002</td>\n",
       "      <td>230.809998</td>\n",
       "      <td>230.850006</td>\n",
       "      <td>75707600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                       Adj Close       Close        High         Low  \\\n",
       "Ticker                           AAPL        AAPL        AAPL        AAPL   \n",
       "Date                                                                        \n",
       "2025-01-02 00:00:00+00:00  243.850006  243.850006  249.100006  241.820007   \n",
       "2025-01-03 00:00:00+00:00  243.360001  243.360001  244.179993  241.889999   \n",
       "2025-01-06 00:00:00+00:00  245.000000  245.000000  247.330002  243.199997   \n",
       "2025-01-07 00:00:00+00:00  242.210007  242.210007  245.550003  241.350006   \n",
       "2025-01-08 00:00:00+00:00  242.699997  242.699997  243.710007  240.050003   \n",
       "2025-01-10 00:00:00+00:00  236.850006  236.850006  240.160004  233.000000   \n",
       "2025-01-13 00:00:00+00:00  234.399994  234.399994  234.669998  229.720001   \n",
       "2025-01-14 00:00:00+00:00  233.279999  233.279999  236.119995  232.470001   \n",
       "2025-01-15 00:00:00+00:00  237.869995  237.869995  238.960007  234.429993   \n",
       "2025-01-16 00:00:00+00:00  228.259995  228.259995  238.009995  228.029999   \n",
       "2025-01-17 00:00:00+00:00  229.979996  229.979996  232.289993  228.479996   \n",
       "2025-01-21 00:00:00+00:00  222.639999  222.639999  224.419998  219.380005   \n",
       "2025-01-22 00:00:00+00:00  223.830002  223.830002  224.119995  219.789993   \n",
       "2025-01-23 00:00:00+00:00  223.660004  223.660004  227.029999  222.300003   \n",
       "2025-01-24 00:00:00+00:00  222.779999  222.779999  225.630005  221.410004   \n",
       "2025-01-27 00:00:00+00:00  229.860001  229.860001  232.149994  223.979996   \n",
       "2025-01-28 00:00:00+00:00  238.259995  238.259995  240.190002  230.809998   \n",
       "\n",
       "Price                            Open    Volume  \n",
       "Ticker                           AAPL      AAPL  \n",
       "Date                                             \n",
       "2025-01-02 00:00:00+00:00  248.929993  55740700  \n",
       "2025-01-03 00:00:00+00:00  243.360001  40244100  \n",
       "2025-01-06 00:00:00+00:00  244.309998  45045600  \n",
       "2025-01-07 00:00:00+00:00  242.979996  40856000  \n",
       "2025-01-08 00:00:00+00:00  241.919998  37628900  \n",
       "2025-01-10 00:00:00+00:00  240.009995  61710900  \n",
       "2025-01-13 00:00:00+00:00  233.529999  49630700  \n",
       "2025-01-14 00:00:00+00:00  234.750000  39435300  \n",
       "2025-01-15 00:00:00+00:00  234.639999  39832000  \n",
       "2025-01-16 00:00:00+00:00  237.350006  71759100  \n",
       "2025-01-17 00:00:00+00:00  232.119995  68488300  \n",
       "2025-01-21 00:00:00+00:00  224.000000  98070400  \n",
       "2025-01-22 00:00:00+00:00  219.789993  64126500  \n",
       "2025-01-23 00:00:00+00:00  224.740005  60234800  \n",
       "2025-01-24 00:00:00+00:00  224.779999  54697900  \n",
       "2025-01-27 00:00:00+00:00  224.020004  94863400  \n",
       "2025-01-28 00:00:00+00:00  230.850006  75707600  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yf.download('AAPL', start = '2025-01-01', end = '2025-01-29')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametrize the download\n",
    "\n",
    "+ Generally, we will look to separate every parameter and setting from functions.\n",
    "+ If we had a few stocks, we could cycle through them. We need a place to store the list of tickers (a db or file, for example).\n",
    "+ Store a csv file with a few stock tickers. The location of the file is a setting, the contents of this file are parameters.\n",
    "+ Use **environment variables** to pass parameters.\n",
    "\n",
    "Start by getting a sample of Information Technology stock tickers by applying subindexing and converting the \"ticker\" column from a pandas object to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all tickers\n",
    "ticker_file = os.getenv(\"TICKERS\")\n",
    "tickers = pd.read_csv(ticker_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can subset our ticker data set using standard indexing techniques. A good reference for this type of data manipulation is Panda's [Documentation](https://pandas.pydata.org/docs/user_guide/indexing.html#indexing-and-selecting-data) and [Cookbook](https://pandas.pydata.org/docs/user_guide/cookbook.html#cookbook-selection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_tech = tickers['GICS Sector'] == 'Information Technology'\n",
    "tech_sector = tickers[idx_tech]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the subset data frame, select one column and convert to list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_tickers = tech_sector['ticker'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  64 of 64 completed\n"
     ]
    }
   ],
   "source": [
    "tech_raw_dt = yf.download(tech_tickers, start = \"2000-01-01\", end = \"2025-01-26\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that we downloaded combines several stocks and prices into a single row. We want to parse this arrangement into a dataframe that contains observations about a single stock on a given day per row. To do this, we can use the function [`stack()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html) and re-arrange the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03 00:00:00+00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.843077</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>1.004464</td>\n",
       "      <td>0.907924</td>\n",
       "      <td>0.936384</td>\n",
       "      <td>535796800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-03 00:00:00+00:00</td>\n",
       "      <td>ACN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03 00:00:00+00:00</td>\n",
       "      <td>ADBE</td>\n",
       "      <td>16.274672</td>\n",
       "      <td>16.390625</td>\n",
       "      <td>16.875000</td>\n",
       "      <td>16.062500</td>\n",
       "      <td>16.812500</td>\n",
       "      <td>7384400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-03 00:00:00+00:00</td>\n",
       "      <td>ADI</td>\n",
       "      <td>28.095684</td>\n",
       "      <td>45.093750</td>\n",
       "      <td>46.937500</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>46.750000</td>\n",
       "      <td>3655600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-03 00:00:00+00:00</td>\n",
       "      <td>ADSK</td>\n",
       "      <td>8.052906</td>\n",
       "      <td>8.343750</td>\n",
       "      <td>8.656250</td>\n",
       "      <td>8.031250</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>2845600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403451</th>\n",
       "      <td>2025-01-24 00:00:00+00:00</td>\n",
       "      <td>TXN</td>\n",
       "      <td>185.520004</td>\n",
       "      <td>185.520004</td>\n",
       "      <td>191.500000</td>\n",
       "      <td>185.029999</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>15856600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403452</th>\n",
       "      <td>2025-01-24 00:00:00+00:00</td>\n",
       "      <td>TYL</td>\n",
       "      <td>591.929993</td>\n",
       "      <td>591.929993</td>\n",
       "      <td>594.969971</td>\n",
       "      <td>590.210022</td>\n",
       "      <td>591.400024</td>\n",
       "      <td>155300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403453</th>\n",
       "      <td>2025-01-24 00:00:00+00:00</td>\n",
       "      <td>VRSN</td>\n",
       "      <td>210.729996</td>\n",
       "      <td>210.729996</td>\n",
       "      <td>210.880005</td>\n",
       "      <td>206.009995</td>\n",
       "      <td>206.020004</td>\n",
       "      <td>563300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403454</th>\n",
       "      <td>2025-01-24 00:00:00+00:00</td>\n",
       "      <td>WDC</td>\n",
       "      <td>67.410004</td>\n",
       "      <td>67.410004</td>\n",
       "      <td>69.440002</td>\n",
       "      <td>67.360001</td>\n",
       "      <td>68.910004</td>\n",
       "      <td>6046500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403455</th>\n",
       "      <td>2025-01-24 00:00:00+00:00</td>\n",
       "      <td>ZBRA</td>\n",
       "      <td>414.609985</td>\n",
       "      <td>414.609985</td>\n",
       "      <td>420.079987</td>\n",
       "      <td>413.739990</td>\n",
       "      <td>419.059998</td>\n",
       "      <td>258900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>403456 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                       Date Ticker   Adj Close       Close        High  \\\n",
       "0      2000-01-03 00:00:00+00:00   AAPL    0.843077    0.999442    1.004464   \n",
       "1      2000-01-03 00:00:00+00:00    ACN         NaN         NaN         NaN   \n",
       "2      2000-01-03 00:00:00+00:00   ADBE   16.274672   16.390625   16.875000   \n",
       "3      2000-01-03 00:00:00+00:00    ADI   28.095684   45.093750   46.937500   \n",
       "4      2000-01-03 00:00:00+00:00   ADSK    8.052906    8.343750    8.656250   \n",
       "...                          ...    ...         ...         ...         ...   \n",
       "403451 2025-01-24 00:00:00+00:00    TXN  185.520004  185.520004  191.500000   \n",
       "403452 2025-01-24 00:00:00+00:00    TYL  591.929993  591.929993  594.969971   \n",
       "403453 2025-01-24 00:00:00+00:00   VRSN  210.729996  210.729996  210.880005   \n",
       "403454 2025-01-24 00:00:00+00:00    WDC   67.410004   67.410004   69.440002   \n",
       "403455 2025-01-24 00:00:00+00:00   ZBRA  414.609985  414.609985  420.079987   \n",
       "\n",
       "Price          Low        Open       Volume  \n",
       "0         0.907924    0.936384  535796800.0  \n",
       "1              NaN         NaN          NaN  \n",
       "2        16.062500   16.812500    7384400.0  \n",
       "3        44.000000   46.750000    3655600.0  \n",
       "4         8.031250    8.500000    2845600.0  \n",
       "...            ...         ...          ...  \n",
       "403451  185.029999  190.000000   15856600.0  \n",
       "403452  590.210022  591.400024     155300.0  \n",
       "403453  206.009995  206.020004     563300.0  \n",
       "403454   67.360001   68.910004    6046500.0  \n",
       "403455  413.739990  419.059998     258900.0  \n",
       "\n",
       "[403456 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, check what tech_raw_dt.stack() looks like.\n",
    "tech_raw_dt.stack(future_stack=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_dt = (tech_raw_dt\n",
    "           .stack(future_stack=True)\n",
    "           .reset_index()\n",
    "           .sort_values(['Ticker', 'Date']))\n",
    "tech_dt.columns.name = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Data in CSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We have some data. How do we store it?\n",
    "+ We can compare two options, CSV and Parqruet, by measuring their performance:\n",
    "\n",
    "    - Time to save.\n",
    "    - Space required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir_size(path='.'):\n",
    "    '''Returns the total size of files contained in path.'''\n",
    "    total = 0\n",
    "    with os.scandir(path) as it:\n",
    "        for entry in it:\n",
    "            if entry.is_file():\n",
    "                total += entry.stat().st_size\n",
    "            elif entry.is_dir():\n",
    "                total += get_dir_size(entry.path)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = os.getenv(\"TEMP_DATA\")\n",
    "os.makedirs(temp, exist_ok=True)\n",
    "stock_path = os.path.join(temp, \"stock_px.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to dt ((403456, 8))csv took 4.234441041946411 seconds.\n",
      "Csv file size 47.818019 MB\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tech_dt.to_csv(stock_path, index = False)\n",
    "end = time.time()\n",
    "\n",
    "print(f'Writing to dt ({tech_dt.shape})csv took {end - start} seconds.')\n",
    "print(f'Csv file size { os.path.getsize(stock_path)*1e-6 } MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data to Parquet\n",
    "\n",
    "### Dask \n",
    "\n",
    "We can work with with large data sets and parquet files. In fact, recent versions of pandas support pyarrow data types and future versions will require a pyarrow backend. The pyarrow library is an interface between Python and the Appache Arrow project. The [parquet data format](https://parquet.apache.org/) and [Arrow](https://arrow.apache.org/docs/python/parquet.html) are projects of the Apache Foundation.\n",
    "\n",
    "However, Dask is much more than an interface to Arrow: Dask provides parallel and distributed computing on pandas-like dataframes. It is also relatively easy to use, bridging a gap between pandas and Spark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jcp_2\\anaconda3\\envs\\dsi_participant\\lib\\site-packages\\dask\\dataframe\\_pyarrow_compat.py:15: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 11.0.0. Please consider upgrading.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dd ((403456, 8)) to parquet took 0.9402008056640625 seconds.\n",
      "Parquet file size 16.595544 MB\n"
     ]
    }
   ],
   "source": [
    "px_dd = dd.from_pandas(tech_dt, npartitions = len(tech_tickers))\n",
    "parquet_path = os.path.join(temp, \"stock_px.parquet\")\n",
    "\n",
    "start = time.time()\n",
    "px_dd.to_parquet(parquet_path, engine = \"pyarrow\")\n",
    "end = time.time()\n",
    "\n",
    "print(f'Writing dd ({tech_dt.shape}) to parquet took {end - start} seconds.')\n",
    "print(f'Parquet file size { get_dir_size(parquet_path)*1e-6 } MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parquet files and Dask Dataframes\n",
    "\n",
    "+ Parquet files are immutable: once written, they cannot be modified.\n",
    "+ Dask DataFrames are a useful implementation to manipulate data stored in parquets.\n",
    "+ Parquet and Dask are not the same: parquet is a file format that can be accessed by many applications and programming languages (Python, R, PowerBI, etc.), while Dask is a package in Python to work with large datasets using distributed computation.\n",
    "+ **Dask is not for everything** (see [Dask DataFrames Best Practices](https://docs.dask.org/en/stable/dataframe-best-practices.html)). \n",
    "\n",
    "    - Consider cases suchas small to large joins, where the small dataframe fits in memory, but the large one does not. \n",
    "    - If possible, use pandas: reduce, then use pandas.\n",
    "    - Pandas performance tips apply to Dask.\n",
    "    - Use the index: it is beneficial to have a well-defined index in Dask DataFrames, as it may speed up searching (filtering) the data. A one-dimensional index is allowed.\n",
    "    - Avoid (or minimize) full-data shuffling: indexing is an expensive operations. \n",
    "    - Some joins are more expensive than others. \n",
    "\n",
    "        * Not expensive:\n",
    "\n",
    "            - Join a Dask DataFrame with a pandas DataFrame.\n",
    "            - Join a Dask DataFrame with another Dask DataFrame of a single partition.\n",
    "            - Join Dask DataFrames along their indexes.\n",
    "\n",
    "        * Expensive:\n",
    "\n",
    "            - Join Dask DataFrames along columns that are not their index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we store prices?\n",
    "\n",
    "+ We can store our data as a single blob. This can be difficult to maintain, especially because parquet files are immutable.\n",
    "+ Strategy: organize data files by ticker and date. Update only latest month.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLean up before start\n",
    "PRICE_DATA = os.getenv(\"PRICE_DATA\")\n",
    "import shutil\n",
    "if os.path.exists(PRICE_DATA):\n",
    "    shutil.rmtree(PRICE_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in tech_dt['Ticker'].unique():\n",
    "    ticker_dt = tech_dt[tech_dt['Ticker'] == ticker]\n",
    "    ticker_dt = ticker_dt.assign(Year = ticker_dt.Date.dt.year)\n",
    "    for yr in ticker_dt['Year'].unique():\n",
    "        yr_dd = dd.from_pandas(ticker_dt[ticker_dt['Year'] == yr],2)\n",
    "        yr_path = os.path.join(PRICE_DATA, ticker, f\"{ticker}_{yr}\")\n",
    "        os.makedirs(os.path.dirname(yr_path), exist_ok=True)\n",
    "        yr_dd.to_parquet(yr_path, engine = \"pyarrow\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why would we want to store data this way?\n",
    "\n",
    "+ Easier to maintain. We do not update old data, only recent data.\n",
    "+ We can also access all files as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, Transform and Save "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "+ Parquet files can be read individually or as a collection.\n",
    "+ `dd.read_parquet()` can take a list (collection) of files as input.\n",
    "+ Use `glob` to get the collection of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "parquet_files = glob(os.path.join(PRICE_DATA, \"**/*.parquet\"), recursive = True)\n",
    "dd_px = dd.read_parquet(parquet_files).set_index(\"Ticker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n",
    "\n",
    "+ This transformation step will create a *Features* data set. In our case, features will be stock returns (we obtained prices).\n",
    "+ Dask dataframes work like pandas dataframes: in particular, we can perform groupby and apply operations.\n",
    "+ Notice the use of [an anonymous (lambda) function](https://realpython.com/python-lambda/) in the apply statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcp_2\\AppData\\Local\\Temp\\ipykernel_5704\\3086392435.py:1: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  dd_shift = dd_px.groupby('Ticker', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "dd_shift = dd_px.groupby('Ticker', group_keys=False).apply(\n",
    "    lambda x: x.assign(Close_lag_1 = x['Close'].shift(1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_rets = dd_shift.assign(\n",
    "    Returns = lambda x: x['Close']/x['Close_lag_1'] - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy Exection\n",
    "\n",
    "What does `dd_rets` contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Year</th>\n",
       "      <th>Close_lag_1</th>\n",
       "      <th>Returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=64</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>datetime64[ns, UTC]</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int32</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACN</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBRA</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBRA</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<div>Dask Name: assign, 9 expressions</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                               Date Adj Close    Close     High      Low     Open   Volume   Year Close_lag_1  Returns\n",
       "npartitions=64                                                                                                        \n",
       "AAPL            datetime64[ns, UTC]   float64  float64  float64  float64  float64  float64  int32     float64  float64\n",
       "ACN                             ...       ...      ...      ...      ...      ...      ...    ...         ...      ...\n",
       "...                             ...       ...      ...      ...      ...      ...      ...    ...         ...      ...\n",
       "ZBRA                            ...       ...      ...      ...      ...      ...      ...    ...         ...      ...\n",
       "ZBRA                            ...       ...      ...      ...      ...      ...      ...    ...         ...      ...\n",
       "Dask Name: assign, 9 expressions\n",
       "Expr=Assign(frame=Assign(frame=GroupByApply(frame=SetIndex(frame=ReadParquetFSSpec(2ba996e), _other='Ticker', options={}), observed=False, group_keys=False, func=<function <lambda> at 0x0000025FCA65FE50>, meta=<no_default>, args=(), kwargs={})))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_rets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Dask is a lazy execution framework: commands will not execute until they are required. \n",
    "+ To trigger an execution in dask use `.compute()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Year</th>\n",
       "      <th>Close_lag_1</th>\n",
       "      <th>Returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2000-01-03 00:00:00+00:00</td>\n",
       "      <td>0.843077</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>1.004464</td>\n",
       "      <td>0.907924</td>\n",
       "      <td>0.936384</td>\n",
       "      <td>535796800.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2000-01-04 00:00:00+00:00</td>\n",
       "      <td>0.771997</td>\n",
       "      <td>0.915179</td>\n",
       "      <td>0.987723</td>\n",
       "      <td>0.903460</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>512377600.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>-0.084310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2000-01-05 00:00:00+00:00</td>\n",
       "      <td>0.783294</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.987165</td>\n",
       "      <td>0.919643</td>\n",
       "      <td>0.926339</td>\n",
       "      <td>778321600.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.915179</td>\n",
       "      <td>0.014633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2000-01-06 00:00:00+00:00</td>\n",
       "      <td>0.715509</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.955357</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.947545</td>\n",
       "      <td>767972800.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>-0.086538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2000-01-07 00:00:00+00:00</td>\n",
       "      <td>0.749402</td>\n",
       "      <td>0.888393</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.852679</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>460734400.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.047369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBRA</th>\n",
       "      <td>2025-01-17 00:00:00+00:00</td>\n",
       "      <td>405.709991</td>\n",
       "      <td>405.709991</td>\n",
       "      <td>407.290009</td>\n",
       "      <td>402.290009</td>\n",
       "      <td>406.040009</td>\n",
       "      <td>270600.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>402.720001</td>\n",
       "      <td>0.007424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBRA</th>\n",
       "      <td>2025-01-21 00:00:00+00:00</td>\n",
       "      <td>418.070007</td>\n",
       "      <td>418.070007</td>\n",
       "      <td>419.850006</td>\n",
       "      <td>407.619995</td>\n",
       "      <td>407.619995</td>\n",
       "      <td>446000.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>405.709991</td>\n",
       "      <td>0.030465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBRA</th>\n",
       "      <td>2025-01-22 00:00:00+00:00</td>\n",
       "      <td>420.570007</td>\n",
       "      <td>420.570007</td>\n",
       "      <td>427.760010</td>\n",
       "      <td>419.589996</td>\n",
       "      <td>425.239990</td>\n",
       "      <td>497500.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>418.070007</td>\n",
       "      <td>0.005980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBRA</th>\n",
       "      <td>2025-01-23 00:00:00+00:00</td>\n",
       "      <td>421.109985</td>\n",
       "      <td>421.109985</td>\n",
       "      <td>422.290009</td>\n",
       "      <td>414.450012</td>\n",
       "      <td>417.619995</td>\n",
       "      <td>377100.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>420.570007</td>\n",
       "      <td>0.001284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBRA</th>\n",
       "      <td>2025-01-24 00:00:00+00:00</td>\n",
       "      <td>414.609985</td>\n",
       "      <td>414.609985</td>\n",
       "      <td>420.079987</td>\n",
       "      <td>413.739990</td>\n",
       "      <td>419.059998</td>\n",
       "      <td>258900.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>421.109985</td>\n",
       "      <td>-0.015435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>403456 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Date   Adj Close       Close        High  \\\n",
       "Ticker                                                                 \n",
       "AAPL   2000-01-03 00:00:00+00:00    0.843077    0.999442    1.004464   \n",
       "AAPL   2000-01-04 00:00:00+00:00    0.771997    0.915179    0.987723   \n",
       "AAPL   2000-01-05 00:00:00+00:00    0.783294    0.928571    0.987165   \n",
       "AAPL   2000-01-06 00:00:00+00:00    0.715509    0.848214    0.955357   \n",
       "AAPL   2000-01-07 00:00:00+00:00    0.749402    0.888393    0.901786   \n",
       "...                          ...         ...         ...         ...   \n",
       "ZBRA   2025-01-17 00:00:00+00:00  405.709991  405.709991  407.290009   \n",
       "ZBRA   2025-01-21 00:00:00+00:00  418.070007  418.070007  419.850006   \n",
       "ZBRA   2025-01-22 00:00:00+00:00  420.570007  420.570007  427.760010   \n",
       "ZBRA   2025-01-23 00:00:00+00:00  421.109985  421.109985  422.290009   \n",
       "ZBRA   2025-01-24 00:00:00+00:00  414.609985  414.609985  420.079987   \n",
       "\n",
       "               Low        Open       Volume  Year  Close_lag_1   Returns  \n",
       "Ticker                                                                    \n",
       "AAPL      0.907924    0.936384  535796800.0  2000          NaN       NaN  \n",
       "AAPL      0.903460    0.966518  512377600.0  2000     0.999442 -0.084310  \n",
       "AAPL      0.919643    0.926339  778321600.0  2000     0.915179  0.014633  \n",
       "AAPL      0.848214    0.947545  767972800.0  2000     0.928571 -0.086538  \n",
       "AAPL      0.852679    0.861607  460734400.0  2000     0.848214  0.047369  \n",
       "...            ...         ...          ...   ...          ...       ...  \n",
       "ZBRA    402.290009  406.040009     270600.0  2025   402.720001  0.007424  \n",
       "ZBRA    407.619995  407.619995     446000.0  2025   405.709991  0.030465  \n",
       "ZBRA    419.589996  425.239990     497500.0  2025   418.070007  0.005980  \n",
       "ZBRA    414.450012  417.619995     377100.0  2025   420.570007  0.001284  \n",
       "ZBRA    413.739990  419.059998     258900.0  2025   421.109985 -0.015435  \n",
       "\n",
       "[403456 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_rets.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save\n",
    "\n",
    "+ Apply transformations to calculate daily returns\n",
    "+ Store the enriched data, the silver dataset, in a new directory.\n",
    "+ Should we keep the same namespace? All columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLean up before save\n",
    "FEATURES_DATA = os.getenv(\"FEATURES_DATA\")\n",
    "if os.path.exists(FEATURES_DATA):\n",
    "    shutil.rmtree(FEATURES_DATA)\n",
    "dd_rets.to_parquet(FEATURES_DATA, overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: from Jupyter to Command Line\n",
    "\n",
    "+ We have drafted our code in a Jupyter Notebook. \n",
    "+ Finalized code should be written in Python modules.\n",
    "\n",
    "## Object Oriented vs Functional Programming\n",
    "\n",
    "+ We can use classes to keep parameters and functions together.\n",
    "+ We *could* use Object Oriented Programming, but parallelization of data manipulation and modelling tasks benefit from *Functional Programming*.\n",
    "+ An Idea: \n",
    "\n",
    "    - [Data Oriented Programming](https://blog.klipse.tech/dop/2022/06/22/principles-of-dop.html).\n",
    "    - Use the class to bundle together parameters and functions.\n",
    "    - Use stateless operations and treat all data objects as immutable (we do not modify them, we overwrite them).\n",
    "    - Take advantage of [`@staticmethod`](https://realpython.com/instance-class-and-static-methods-demystified/).\n",
    "\n",
    "The code is in `./05_src/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our original design was:\n",
    "\n",
    "![](./images/02_target_pipeline_manager.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataManager` class in `./05_src/data_manager.py` is a simple implementation of the ideas and code discussed in this notebook. The lines below will download data for about 500 stocks from the S&P500. Using this data a few features will be created and stored in the features data set.\n",
    "\n",
    "First, instantiate an object of class `DataManager`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_manager import DataManager\n",
    "dm = DataManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download all prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 20:04:16,935, data_manager.py, 42, INFO, Getting price data for all tickers.\n",
      "2025-01-30 20:04:16,938, data_manager.py, 51, INFO, Getting tickers from ../../05_src/data/tickers/sp500_wiki.csv\n",
      "2025-01-30 20:04:16,949, data_manager.py, 57, INFO, Processing all tickers\n",
      "2025-01-30 20:04:16,952, data_manager.py, 70, INFO, Processing ticker ['MMM', 'AOS', 'ABT', 'ABBV', 'ACN', 'ADBE', 'AMD', 'AES', 'AFL', 'A', 'APD', 'ABNB', 'AKAM', 'ALB', 'ARE', 'ALGN', 'ALLE', 'LNT', 'ALL', 'GOOGL', 'GOOG', 'MO', 'AMZN', 'AMCR', 'AEE', 'AAL', 'AEP', 'AXP', 'AIG', 'AMT', 'AWK', 'AMP', 'AME', 'AMGN', 'APH', 'ADI', 'ANSS', 'AON', 'APA', 'AAPL', 'AMAT', 'APTV', 'ACGL', 'ADM', 'ANET', 'AJG', 'AIZ', 'T', 'ATO', 'ADSK', 'ADP', 'AZO', 'AVB', 'AVY', 'AXON', 'BKR', 'BALL', 'BAC', 'BK', 'BBWI', 'BAX', 'BDX', 'BRK.B', 'BBY', 'BIO', 'TECH', 'BIIB', 'BLK', 'BX', 'BA', 'BKNG', 'BWA', 'BXP', 'BSX', 'BMY', 'AVGO', 'BR', 'BRO', 'BF.B', 'BLDR', 'BG', 'CDNS', 'CZR', 'CPT', 'CPB', 'COF', 'CAH', 'KMX', 'CCL', 'CARR', 'CTLT', 'CAT', 'CBOE', 'CBRE', 'CDW', 'CE', 'COR', 'CNC', 'CNP', 'CF', 'CHRW', 'CRL', 'SCHW', 'CHTR', 'CVX', 'CMG', 'CB', 'CHD', 'CI', 'CINF', 'CTAS', 'CSCO', 'C', 'CFG', 'CLX', 'CME', 'CMS', 'KO', 'CTSH', 'CL', 'CMCSA', 'CMA', 'CAG', 'COP', 'ED', 'STZ', 'CEG', 'COO', 'CPRT', 'GLW', 'CTVA', 'CSGP', 'COST', 'CTRA', 'CCI', 'CSX', 'CMI', 'CVS', 'DHR', 'DRI', 'DVA', 'DAY', 'DE', 'DAL', 'XRAY', 'DVN', 'DXCM', 'FANG', 'DLR', 'DFS', 'DG', 'DLTR', 'D', 'DPZ', 'DOV', 'DOW', 'DHI', 'DTE', 'DUK', 'DD', 'EMN', 'ETN', 'EBAY', 'ECL', 'EIX', 'EW', 'EA', 'ELV', 'LLY', 'EMR', 'ENPH', 'ETR', 'EOG', 'EPAM', 'EQT', 'EFX', 'EQIX', 'EQR', 'ESS', 'EL', 'ETSY', 'EG', 'EVRG', 'ES', 'EXC', 'EXPE', 'EXPD', 'EXR', 'XOM', 'FFIV', 'FDS', 'FICO', 'FAST', 'FRT', 'FDX', 'FIS', 'FITB', 'FSLR', 'FE', 'FI', 'FLT', 'FMC', 'F', 'FTNT', 'FTV', 'FOXA', 'FOX', 'BEN', 'FCX', 'GRMN', 'IT', 'GEHC', 'GEN', 'GNRC', 'GD', 'GE', 'GIS', 'GM', 'GPC', 'GILD', 'GPN', 'GL', 'GS', 'HAL', 'HIG', 'HAS', 'HCA', 'PEAK', 'HSIC', 'HSY', 'HES', 'HPE', 'HLT', 'HOLX', 'HD', 'HON', 'HRL', 'HST', 'HWM', 'HPQ', 'HUBB', 'HUM', 'HBAN', 'HII', 'IBM', 'IEX', 'IDXX', 'ITW', 'ILMN', 'INCY', 'IR', 'PODD', 'INTC', 'ICE', 'IFF', 'IP', 'IPG', 'INTU', 'ISRG', 'IVZ', 'INVH', 'IQV', 'IRM', 'JBHT', 'JBL', 'JKHY', 'J', 'JNJ', 'JCI', 'JPM', 'JNPR', 'K', 'KVUE', 'KDP', 'KEY', 'KEYS', 'KMB', 'KIM', 'KMI', 'KLAC', 'KHC', 'KR', 'LHX', 'LH', 'LRCX', 'LW', 'LVS', 'LDOS', 'LEN', 'LIN', 'LYV', 'LKQ', 'LMT', 'L', 'LOW', 'LULU', 'LYB', 'MTB', 'MRO', 'MPC', 'MKTX', 'MAR', 'MMC', 'MLM', 'MAS', 'MA', 'MTCH', 'MKC', 'MCD', 'MCK', 'MDT', 'MRK', 'META', 'MET', 'MTD', 'MGM', 'MCHP', 'MU', 'MSFT', 'MAA', 'MRNA', 'MHK', 'MOH', 'TAP', 'MDLZ', 'MPWR', 'MNST', 'MCO', 'MS', 'MOS', 'MSI', 'MSCI', 'NDAQ', 'NTAP', 'NFLX', 'NEM', 'NWSA', 'NWS', 'NEE', 'NKE', 'NI', 'NDSN', 'NSC', 'NTRS', 'NOC', 'NCLH', 'NRG', 'NUE', 'NVDA', 'NVR', 'NXPI', 'ORLY', 'OXY', 'ODFL', 'OMC', 'ON', 'OKE', 'ORCL', 'OTIS', 'PCAR', 'PKG', 'PANW', 'PARA', 'PH', 'PAYX', 'PAYC', 'PYPL', 'PNR', 'PEP', 'PFE', 'PCG', 'PM', 'PSX', 'PNW', 'PXD', 'PNC', 'POOL', 'PPG', 'PPL', 'PFG', 'PG', 'PGR', 'PLD', 'PRU', 'PEG', 'PTC', 'PSA', 'PHM', 'QRVO', 'PWR', 'QCOM', 'DGX', 'RL', 'RJF', 'RTX', 'O', 'REG', 'REGN', 'RF', 'RSG', 'RMD', 'RVTY', 'RHI', 'ROK', 'ROL', 'ROP', 'ROST', 'RCL', 'SPGI', 'CRM', 'SBAC', 'SLB', 'STX', 'SRE', 'NOW', 'SHW', 'SPG', 'SWKS', 'SJM', 'SNA', 'SO', 'LUV', 'SWK', 'SBUX', 'STT', 'STLD', 'STE', 'SYK', 'SYF', 'SNPS', 'SYY', 'TMUS', 'TROW', 'TTWO', 'TPR', 'TRGP', 'TGT', 'TEL', 'TDY', 'TFX', 'TER', 'TSLA', 'TXN', 'TXT', 'TMO', 'TJX', 'TSCO', 'TT', 'TDG', 'TRV', 'TRMB', 'TFC', 'TYL', 'TSN', 'USB', 'UBER', 'UDR', 'ULTA', 'UNP', 'UAL', 'UPS', 'URI', 'UNH', 'UHS', 'VLO', 'VTR', 'VLTO', 'VRSN', 'VRSK', 'VZ', 'VRTX', 'VFC', 'VTRS', 'VICI', 'V', 'VMC', 'WRB', 'WAB', 'WBA', 'WMT', 'DIS', 'WBD', 'WM', 'WAT', 'WEC', 'WFC', 'WELL', 'WST', 'WDC', 'WRK', 'WY', 'WHR', 'WMB', 'WTW', 'GWW', 'WYNN', 'XEL', 'XYL', 'YUM', 'ZBRA', 'ZBH', 'ZION', 'ZTS']\n",
      "2025-01-30 20:04:16,954, data_manager.py, 100, INFO, Getting stock price data for ['MMM', 'AOS', 'ABT', 'ABBV', 'ACN', 'ADBE', 'AMD', 'AES', 'AFL', 'A', 'APD', 'ABNB', 'AKAM', 'ALB', 'ARE', 'ALGN', 'ALLE', 'LNT', 'ALL', 'GOOGL', 'GOOG', 'MO', 'AMZN', 'AMCR', 'AEE', 'AAL', 'AEP', 'AXP', 'AIG', 'AMT', 'AWK', 'AMP', 'AME', 'AMGN', 'APH', 'ADI', 'ANSS', 'AON', 'APA', 'AAPL', 'AMAT', 'APTV', 'ACGL', 'ADM', 'ANET', 'AJG', 'AIZ', 'T', 'ATO', 'ADSK', 'ADP', 'AZO', 'AVB', 'AVY', 'AXON', 'BKR', 'BALL', 'BAC', 'BK', 'BBWI', 'BAX', 'BDX', 'BRK.B', 'BBY', 'BIO', 'TECH', 'BIIB', 'BLK', 'BX', 'BA', 'BKNG', 'BWA', 'BXP', 'BSX', 'BMY', 'AVGO', 'BR', 'BRO', 'BF.B', 'BLDR', 'BG', 'CDNS', 'CZR', 'CPT', 'CPB', 'COF', 'CAH', 'KMX', 'CCL', 'CARR', 'CTLT', 'CAT', 'CBOE', 'CBRE', 'CDW', 'CE', 'COR', 'CNC', 'CNP', 'CF', 'CHRW', 'CRL', 'SCHW', 'CHTR', 'CVX', 'CMG', 'CB', 'CHD', 'CI', 'CINF', 'CTAS', 'CSCO', 'C', 'CFG', 'CLX', 'CME', 'CMS', 'KO', 'CTSH', 'CL', 'CMCSA', 'CMA', 'CAG', 'COP', 'ED', 'STZ', 'CEG', 'COO', 'CPRT', 'GLW', 'CTVA', 'CSGP', 'COST', 'CTRA', 'CCI', 'CSX', 'CMI', 'CVS', 'DHR', 'DRI', 'DVA', 'DAY', 'DE', 'DAL', 'XRAY', 'DVN', 'DXCM', 'FANG', 'DLR', 'DFS', 'DG', 'DLTR', 'D', 'DPZ', 'DOV', 'DOW', 'DHI', 'DTE', 'DUK', 'DD', 'EMN', 'ETN', 'EBAY', 'ECL', 'EIX', 'EW', 'EA', 'ELV', 'LLY', 'EMR', 'ENPH', 'ETR', 'EOG', 'EPAM', 'EQT', 'EFX', 'EQIX', 'EQR', 'ESS', 'EL', 'ETSY', 'EG', 'EVRG', 'ES', 'EXC', 'EXPE', 'EXPD', 'EXR', 'XOM', 'FFIV', 'FDS', 'FICO', 'FAST', 'FRT', 'FDX', 'FIS', 'FITB', 'FSLR', 'FE', 'FI', 'FLT', 'FMC', 'F', 'FTNT', 'FTV', 'FOXA', 'FOX', 'BEN', 'FCX', 'GRMN', 'IT', 'GEHC', 'GEN', 'GNRC', 'GD', 'GE', 'GIS', 'GM', 'GPC', 'GILD', 'GPN', 'GL', 'GS', 'HAL', 'HIG', 'HAS', 'HCA', 'PEAK', 'HSIC', 'HSY', 'HES', 'HPE', 'HLT', 'HOLX', 'HD', 'HON', 'HRL', 'HST', 'HWM', 'HPQ', 'HUBB', 'HUM', 'HBAN', 'HII', 'IBM', 'IEX', 'IDXX', 'ITW', 'ILMN', 'INCY', 'IR', 'PODD', 'INTC', 'ICE', 'IFF', 'IP', 'IPG', 'INTU', 'ISRG', 'IVZ', 'INVH', 'IQV', 'IRM', 'JBHT', 'JBL', 'JKHY', 'J', 'JNJ', 'JCI', 'JPM', 'JNPR', 'K', 'KVUE', 'KDP', 'KEY', 'KEYS', 'KMB', 'KIM', 'KMI', 'KLAC', 'KHC', 'KR', 'LHX', 'LH', 'LRCX', 'LW', 'LVS', 'LDOS', 'LEN', 'LIN', 'LYV', 'LKQ', 'LMT', 'L', 'LOW', 'LULU', 'LYB', 'MTB', 'MRO', 'MPC', 'MKTX', 'MAR', 'MMC', 'MLM', 'MAS', 'MA', 'MTCH', 'MKC', 'MCD', 'MCK', 'MDT', 'MRK', 'META', 'MET', 'MTD', 'MGM', 'MCHP', 'MU', 'MSFT', 'MAA', 'MRNA', 'MHK', 'MOH', 'TAP', 'MDLZ', 'MPWR', 'MNST', 'MCO', 'MS', 'MOS', 'MSI', 'MSCI', 'NDAQ', 'NTAP', 'NFLX', 'NEM', 'NWSA', 'NWS', 'NEE', 'NKE', 'NI', 'NDSN', 'NSC', 'NTRS', 'NOC', 'NCLH', 'NRG', 'NUE', 'NVDA', 'NVR', 'NXPI', 'ORLY', 'OXY', 'ODFL', 'OMC', 'ON', 'OKE', 'ORCL', 'OTIS', 'PCAR', 'PKG', 'PANW', 'PARA', 'PH', 'PAYX', 'PAYC', 'PYPL', 'PNR', 'PEP', 'PFE', 'PCG', 'PM', 'PSX', 'PNW', 'PXD', 'PNC', 'POOL', 'PPG', 'PPL', 'PFG', 'PG', 'PGR', 'PLD', 'PRU', 'PEG', 'PTC', 'PSA', 'PHM', 'QRVO', 'PWR', 'QCOM', 'DGX', 'RL', 'RJF', 'RTX', 'O', 'REG', 'REGN', 'RF', 'RSG', 'RMD', 'RVTY', 'RHI', 'ROK', 'ROL', 'ROP', 'ROST', 'RCL', 'SPGI', 'CRM', 'SBAC', 'SLB', 'STX', 'SRE', 'NOW', 'SHW', 'SPG', 'SWKS', 'SJM', 'SNA', 'SO', 'LUV', 'SWK', 'SBUX', 'STT', 'STLD', 'STE', 'SYK', 'SYF', 'SNPS', 'SYY', 'TMUS', 'TROW', 'TTWO', 'TPR', 'TRGP', 'TGT', 'TEL', 'TDY', 'TFX', 'TER', 'TSLA', 'TXN', 'TXT', 'TMO', 'TJX', 'TSCO', 'TT', 'TDG', 'TRV', 'TRMB', 'TFC', 'TYL', 'TSN', 'USB', 'UBER', 'UDR', 'ULTA', 'UNP', 'UAL', 'UPS', 'URI', 'UNH', 'UHS', 'VLO', 'VTR', 'VLTO', 'VRSN', 'VRSK', 'VZ', 'VRTX', 'VFC', 'VTRS', 'VICI', 'V', 'VMC', 'WRB', 'WAB', 'WBA', 'WMT', 'DIS', 'WBD', 'WM', 'WAT', 'WEC', 'WFC', 'WELL', 'WST', 'WDC', 'WRK', 'WY', 'WHR', 'WMB', 'WTW', 'GWW', 'WYNN', 'XEL', 'XYL', 'YUM', 'ZBRA', 'ZBH', 'ZION', 'ZTS'] from 2000-01-01 to 2025-01-30\n",
      "[*********************100%***********************]  503 of 503 completed\n",
      "\n",
      "7 Failed downloads:\n",
      "['MRO', 'WRK', 'PXD', 'BRK.B', 'FLT', 'PEAK']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "['BF.B']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1d 2000-01-01 -> 2025-01-30)')\n",
      "2025-01-30 20:05:11,036, data_manager.py, 80, INFO, Saving data by year\n",
      "2025-01-30 20:05:11,366, data_manager.py, 83, INFO, Saving data for A\n",
      "2025-01-30 20:05:12,004, data_manager.py, 83, INFO, Saving data for AAL\n",
      "2025-01-30 20:05:12,592, data_manager.py, 83, INFO, Saving data for AAPL\n",
      "2025-01-30 20:05:13,290, data_manager.py, 83, INFO, Saving data for ABBV\n",
      "2025-01-30 20:05:14,014, data_manager.py, 83, INFO, Saving data for ABNB\n",
      "2025-01-30 20:05:14,738, data_manager.py, 83, INFO, Saving data for ABT\n",
      "2025-01-30 20:05:15,337, data_manager.py, 83, INFO, Saving data for ACGL\n",
      "2025-01-30 20:05:15,904, data_manager.py, 83, INFO, Saving data for ACN\n",
      "2025-01-30 20:05:16,482, data_manager.py, 83, INFO, Saving data for ADBE\n",
      "2025-01-30 20:05:17,103, data_manager.py, 83, INFO, Saving data for ADI\n",
      "2025-01-30 20:05:17,732, data_manager.py, 83, INFO, Saving data for ADM\n",
      "2025-01-30 20:05:18,528, data_manager.py, 83, INFO, Saving data for ADP\n",
      "2025-01-30 20:05:19,268, data_manager.py, 83, INFO, Saving data for ADSK\n",
      "2025-01-30 20:05:20,027, data_manager.py, 83, INFO, Saving data for AEE\n",
      "2025-01-30 20:05:20,696, data_manager.py, 83, INFO, Saving data for AEP\n",
      "2025-01-30 20:05:21,261, data_manager.py, 83, INFO, Saving data for AES\n",
      "2025-01-30 20:05:21,801, data_manager.py, 83, INFO, Saving data for AFL\n",
      "2025-01-30 20:05:22,355, data_manager.py, 83, INFO, Saving data for AIG\n",
      "2025-01-30 20:05:22,892, data_manager.py, 83, INFO, Saving data for AIZ\n",
      "2025-01-30 20:05:23,438, data_manager.py, 83, INFO, Saving data for AJG\n",
      "2025-01-30 20:05:23,999, data_manager.py, 83, INFO, Saving data for AKAM\n",
      "2025-01-30 20:05:24,588, data_manager.py, 83, INFO, Saving data for ALB\n",
      "2025-01-30 20:05:25,205, data_manager.py, 83, INFO, Saving data for ALGN\n",
      "2025-01-30 20:05:25,830, data_manager.py, 83, INFO, Saving data for ALL\n",
      "2025-01-30 20:05:26,393, data_manager.py, 83, INFO, Saving data for ALLE\n",
      "2025-01-30 20:05:26,967, data_manager.py, 83, INFO, Saving data for AMAT\n",
      "2025-01-30 20:05:27,663, data_manager.py, 83, INFO, Saving data for AMCR\n",
      "2025-01-30 20:05:28,249, data_manager.py, 83, INFO, Saving data for AMD\n",
      "2025-01-30 20:05:28,913, data_manager.py, 83, INFO, Saving data for AME\n",
      "2025-01-30 20:05:29,530, data_manager.py, 83, INFO, Saving data for AMGN\n",
      "2025-01-30 20:05:30,178, data_manager.py, 83, INFO, Saving data for AMP\n",
      "2025-01-30 20:05:32,804, data_manager.py, 83, INFO, Saving data for AMT\n",
      "2025-01-30 20:05:33,402, data_manager.py, 83, INFO, Saving data for AMZN\n",
      "2025-01-30 20:05:34,019, data_manager.py, 83, INFO, Saving data for ANET\n",
      "2025-01-30 20:05:34,573, data_manager.py, 83, INFO, Saving data for ANSS\n",
      "2025-01-30 20:05:35,196, data_manager.py, 83, INFO, Saving data for AON\n",
      "2025-01-30 20:05:35,764, data_manager.py, 83, INFO, Saving data for AOS\n",
      "2025-01-30 20:05:36,341, data_manager.py, 83, INFO, Saving data for APA\n",
      "2025-01-30 20:05:36,938, data_manager.py, 83, INFO, Saving data for APD\n",
      "2025-01-30 20:05:37,567, data_manager.py, 83, INFO, Saving data for APH\n",
      "2025-01-30 20:05:38,264, data_manager.py, 83, INFO, Saving data for APTV\n",
      "2025-01-30 20:05:38,924, data_manager.py, 83, INFO, Saving data for ARE\n",
      "2025-01-30 20:05:39,588, data_manager.py, 83, INFO, Saving data for ATO\n",
      "2025-01-30 20:05:40,220, data_manager.py, 83, INFO, Saving data for AVB\n",
      "2025-01-30 20:05:40,875, data_manager.py, 83, INFO, Saving data for AVGO\n",
      "2025-01-30 20:05:41,523, data_manager.py, 83, INFO, Saving data for AVY\n",
      "2025-01-30 20:05:42,150, data_manager.py, 83, INFO, Saving data for AWK\n",
      "2025-01-30 20:05:42,743, data_manager.py, 83, INFO, Saving data for AXON\n",
      "2025-01-30 20:05:43,338, data_manager.py, 83, INFO, Saving data for AXP\n",
      "2025-01-30 20:05:43,957, data_manager.py, 83, INFO, Saving data for AZO\n",
      "2025-01-30 20:05:44,748, data_manager.py, 83, INFO, Saving data for BA\n",
      "2025-01-30 20:05:45,488, data_manager.py, 83, INFO, Saving data for BAC\n",
      "2025-01-30 20:05:46,390, data_manager.py, 83, INFO, Saving data for BALL\n",
      "2025-01-30 20:05:47,064, data_manager.py, 83, INFO, Saving data for BAX\n",
      "2025-01-30 20:05:47,821, data_manager.py, 83, INFO, Saving data for BBWI\n",
      "2025-01-30 20:05:48,533, data_manager.py, 83, INFO, Saving data for BBY\n",
      "2025-01-30 20:05:49,229, data_manager.py, 83, INFO, Saving data for BDX\n",
      "2025-01-30 20:05:49,863, data_manager.py, 83, INFO, Saving data for BEN\n",
      "2025-01-30 20:05:50,573, data_manager.py, 83, INFO, Saving data for BF.B\n",
      "2025-01-30 20:05:51,185, data_manager.py, 83, INFO, Saving data for BG\n",
      "2025-01-30 20:05:51,781, data_manager.py, 83, INFO, Saving data for BIIB\n",
      "2025-01-30 20:05:52,386, data_manager.py, 83, INFO, Saving data for BIO\n",
      "2025-01-30 20:05:53,048, data_manager.py, 83, INFO, Saving data for BK\n",
      "2025-01-30 20:05:53,594, data_manager.py, 83, INFO, Saving data for BKNG\n",
      "2025-01-30 20:05:54,204, data_manager.py, 83, INFO, Saving data for BKR\n",
      "2025-01-30 20:05:54,784, data_manager.py, 83, INFO, Saving data for BLDR\n",
      "2025-01-30 20:05:55,353, data_manager.py, 83, INFO, Saving data for BLK\n",
      "2025-01-30 20:05:55,971, data_manager.py, 83, INFO, Saving data for BMY\n",
      "2025-01-30 20:05:56,573, data_manager.py, 83, INFO, Saving data for BR\n",
      "2025-01-30 20:05:57,184, data_manager.py, 83, INFO, Saving data for BRK.B\n",
      "2025-01-30 20:05:57,847, data_manager.py, 83, INFO, Saving data for BRO\n",
      "2025-01-30 20:05:58,410, data_manager.py, 83, INFO, Saving data for BSX\n",
      "2025-01-30 20:05:58,955, data_manager.py, 83, INFO, Saving data for BWA\n",
      "2025-01-30 20:05:59,544, data_manager.py, 83, INFO, Saving data for BX\n",
      "2025-01-30 20:06:00,088, data_manager.py, 83, INFO, Saving data for BXP\n",
      "2025-01-30 20:06:00,706, data_manager.py, 83, INFO, Saving data for C\n",
      "2025-01-30 20:06:01,277, data_manager.py, 83, INFO, Saving data for CAG\n",
      "2025-01-30 20:06:01,834, data_manager.py, 83, INFO, Saving data for CAH\n",
      "2025-01-30 20:06:02,399, data_manager.py, 83, INFO, Saving data for CARR\n",
      "2025-01-30 20:06:02,967, data_manager.py, 83, INFO, Saving data for CAT\n",
      "2025-01-30 20:06:03,572, data_manager.py, 83, INFO, Saving data for CB\n",
      "2025-01-30 20:06:04,118, data_manager.py, 83, INFO, Saving data for CBOE\n",
      "2025-01-30 20:06:04,673, data_manager.py, 83, INFO, Saving data for CBRE\n",
      "2025-01-30 20:06:05,257, data_manager.py, 83, INFO, Saving data for CCI\n",
      "2025-01-30 20:06:05,803, data_manager.py, 83, INFO, Saving data for CCL\n",
      "2025-01-30 20:06:06,371, data_manager.py, 83, INFO, Saving data for CDNS\n",
      "2025-01-30 20:06:06,947, data_manager.py, 83, INFO, Saving data for CDW\n",
      "2025-01-30 20:06:07,530, data_manager.py, 83, INFO, Saving data for CE\n",
      "2025-01-30 20:06:08,050, data_manager.py, 83, INFO, Saving data for CEG\n",
      "2025-01-30 20:06:08,577, data_manager.py, 83, INFO, Saving data for CF\n",
      "2025-01-30 20:06:09,139, data_manager.py, 83, INFO, Saving data for CFG\n",
      "2025-01-30 20:06:09,716, data_manager.py, 83, INFO, Saving data for CHD\n",
      "2025-01-30 20:06:10,266, data_manager.py, 83, INFO, Saving data for CHRW\n",
      "2025-01-30 20:06:10,823, data_manager.py, 83, INFO, Saving data for CHTR\n",
      "2025-01-30 20:06:11,362, data_manager.py, 83, INFO, Saving data for CI\n",
      "2025-01-30 20:06:11,906, data_manager.py, 83, INFO, Saving data for CINF\n",
      "2025-01-30 20:06:12,482, data_manager.py, 83, INFO, Saving data for CL\n",
      "2025-01-30 20:06:13,023, data_manager.py, 83, INFO, Saving data for CLX\n",
      "2025-01-30 20:06:13,575, data_manager.py, 83, INFO, Saving data for CMA\n",
      "2025-01-30 20:06:14,201, data_manager.py, 83, INFO, Saving data for CMCSA\n",
      "2025-01-30 20:06:14,761, data_manager.py, 83, INFO, Saving data for CME\n",
      "2025-01-30 20:06:15,429, data_manager.py, 83, INFO, Saving data for CMG\n",
      "2025-01-30 20:06:16,042, data_manager.py, 83, INFO, Saving data for CMI\n",
      "2025-01-30 20:06:16,702, data_manager.py, 83, INFO, Saving data for CMS\n",
      "2025-01-30 20:06:17,288, data_manager.py, 83, INFO, Saving data for CNC\n",
      "2025-01-30 20:06:17,837, data_manager.py, 83, INFO, Saving data for CNP\n",
      "2025-01-30 20:06:18,437, data_manager.py, 83, INFO, Saving data for COF\n",
      "2025-01-30 20:06:19,102, data_manager.py, 83, INFO, Saving data for COO\n",
      "2025-01-30 20:06:19,752, data_manager.py, 83, INFO, Saving data for COP\n",
      "2025-01-30 20:06:20,314, data_manager.py, 83, INFO, Saving data for COR\n",
      "2025-01-30 20:06:20,906, data_manager.py, 83, INFO, Saving data for COST\n",
      "2025-01-30 20:06:21,489, data_manager.py, 83, INFO, Saving data for CPB\n",
      "2025-01-30 20:06:22,138, data_manager.py, 83, INFO, Saving data for CPRT\n",
      "2025-01-30 20:06:22,802, data_manager.py, 83, INFO, Saving data for CPT\n",
      "2025-01-30 20:06:23,341, data_manager.py, 83, INFO, Saving data for CRL\n",
      "2025-01-30 20:06:23,926, data_manager.py, 83, INFO, Saving data for CRM\n",
      "2025-01-30 20:06:24,500, data_manager.py, 83, INFO, Saving data for CSCO\n",
      "2025-01-30 20:06:25,111, data_manager.py, 83, INFO, Saving data for CSGP\n",
      "2025-01-30 20:06:25,708, data_manager.py, 83, INFO, Saving data for CSX\n",
      "2025-01-30 20:06:26,370, data_manager.py, 83, INFO, Saving data for CTAS\n",
      "2025-01-30 20:06:26,980, data_manager.py, 83, INFO, Saving data for CTLT\n",
      "2025-01-30 20:06:27,588, data_manager.py, 83, INFO, Saving data for CTRA\n",
      "2025-01-30 20:06:28,161, data_manager.py, 83, INFO, Saving data for CTSH\n",
      "2025-01-30 20:06:28,758, data_manager.py, 83, INFO, Saving data for CTVA\n",
      "2025-01-30 20:06:29,415, data_manager.py, 83, INFO, Saving data for CVS\n",
      "2025-01-30 20:06:30,000, data_manager.py, 83, INFO, Saving data for CVX\n",
      "2025-01-30 20:06:30,613, data_manager.py, 83, INFO, Saving data for CZR\n",
      "2025-01-30 20:06:31,221, data_manager.py, 83, INFO, Saving data for D\n",
      "2025-01-30 20:06:31,832, data_manager.py, 83, INFO, Saving data for DAL\n",
      "2025-01-30 20:06:32,393, data_manager.py, 83, INFO, Saving data for DAY\n",
      "2025-01-30 20:06:32,941, data_manager.py, 83, INFO, Saving data for DD\n",
      "2025-01-30 20:06:33,453, data_manager.py, 83, INFO, Saving data for DE\n",
      "2025-01-30 20:06:34,043, data_manager.py, 83, INFO, Saving data for DFS\n",
      "2025-01-30 20:06:34,588, data_manager.py, 83, INFO, Saving data for DG\n",
      "2025-01-30 20:06:35,108, data_manager.py, 83, INFO, Saving data for DGX\n",
      "2025-01-30 20:06:35,654, data_manager.py, 83, INFO, Saving data for DHI\n",
      "2025-01-30 20:06:36,232, data_manager.py, 83, INFO, Saving data for DHR\n",
      "2025-01-30 20:06:36,810, data_manager.py, 83, INFO, Saving data for DIS\n",
      "2025-01-30 20:06:37,350, data_manager.py, 83, INFO, Saving data for DLR\n",
      "2025-01-30 20:06:37,924, data_manager.py, 83, INFO, Saving data for DLTR\n",
      "2025-01-30 20:06:38,487, data_manager.py, 83, INFO, Saving data for DOV\n",
      "2025-01-30 20:06:39,089, data_manager.py, 83, INFO, Saving data for DOW\n",
      "2025-01-30 20:06:39,640, data_manager.py, 83, INFO, Saving data for DPZ\n",
      "2025-01-30 20:06:40,224, data_manager.py, 83, INFO, Saving data for DRI\n",
      "2025-01-30 20:06:40,794, data_manager.py, 83, INFO, Saving data for DTE\n",
      "2025-01-30 20:06:41,396, data_manager.py, 83, INFO, Saving data for DUK\n",
      "2025-01-30 20:06:42,039, data_manager.py, 83, INFO, Saving data for DVA\n",
      "2025-01-30 20:06:42,656, data_manager.py, 83, INFO, Saving data for DVN\n",
      "2025-01-30 20:06:43,278, data_manager.py, 83, INFO, Saving data for DXCM\n",
      "2025-01-30 20:06:43,905, data_manager.py, 83, INFO, Saving data for EA\n",
      "2025-01-30 20:06:44,552, data_manager.py, 83, INFO, Saving data for EBAY\n",
      "2025-01-30 20:06:45,179, data_manager.py, 83, INFO, Saving data for ECL\n",
      "2025-01-30 20:06:45,833, data_manager.py, 83, INFO, Saving data for ED\n",
      "2025-01-30 20:06:46,492, data_manager.py, 83, INFO, Saving data for EFX\n",
      "2025-01-30 20:06:47,180, data_manager.py, 83, INFO, Saving data for EG\n",
      "2025-01-30 20:06:47,754, data_manager.py, 83, INFO, Saving data for EIX\n",
      "2025-01-30 20:06:48,342, data_manager.py, 83, INFO, Saving data for EL\n",
      "2025-01-30 20:06:48,931, data_manager.py, 83, INFO, Saving data for ELV\n",
      "2025-01-30 20:06:49,551, data_manager.py, 83, INFO, Saving data for EMN\n",
      "2025-01-30 20:06:50,180, data_manager.py, 83, INFO, Saving data for EMR\n",
      "2025-01-30 20:06:50,902, data_manager.py, 83, INFO, Saving data for ENPH\n",
      "2025-01-30 20:06:51,620, data_manager.py, 83, INFO, Saving data for EOG\n",
      "2025-01-30 20:06:52,269, data_manager.py, 83, INFO, Saving data for EPAM\n",
      "2025-01-30 20:06:52,917, data_manager.py, 83, INFO, Saving data for EQIX\n",
      "2025-01-30 20:06:53,579, data_manager.py, 83, INFO, Saving data for EQR\n",
      "2025-01-30 20:06:54,178, data_manager.py, 83, INFO, Saving data for EQT\n",
      "2025-01-30 20:06:54,904, data_manager.py, 83, INFO, Saving data for ES\n",
      "2025-01-30 20:06:55,569, data_manager.py, 83, INFO, Saving data for ESS\n",
      "2025-01-30 20:06:56,184, data_manager.py, 83, INFO, Saving data for ETN\n",
      "2025-01-30 20:06:56,813, data_manager.py, 83, INFO, Saving data for ETR\n",
      "2025-01-30 20:06:57,500, data_manager.py, 83, INFO, Saving data for ETSY\n",
      "2025-01-30 20:06:58,136, data_manager.py, 83, INFO, Saving data for EVRG\n",
      "2025-01-30 20:06:58,863, data_manager.py, 83, INFO, Saving data for EW\n",
      "2025-01-30 20:06:59,484, data_manager.py, 83, INFO, Saving data for EXC\n",
      "2025-01-30 20:07:00,141, data_manager.py, 83, INFO, Saving data for EXPD\n",
      "2025-01-30 20:07:00,710, data_manager.py, 83, INFO, Saving data for EXPE\n",
      "2025-01-30 20:07:01,343, data_manager.py, 83, INFO, Saving data for EXR\n",
      "2025-01-30 20:07:01,983, data_manager.py, 83, INFO, Saving data for F\n",
      "2025-01-30 20:07:02,528, data_manager.py, 83, INFO, Saving data for FANG\n",
      "2025-01-30 20:07:03,123, data_manager.py, 83, INFO, Saving data for FAST\n",
      "2025-01-30 20:07:03,713, data_manager.py, 83, INFO, Saving data for FCX\n",
      "2025-01-30 20:07:04,260, data_manager.py, 83, INFO, Saving data for FDS\n",
      "2025-01-30 20:07:04,809, data_manager.py, 83, INFO, Saving data for FDX\n",
      "2025-01-30 20:07:05,355, data_manager.py, 83, INFO, Saving data for FE\n",
      "2025-01-30 20:07:05,909, data_manager.py, 83, INFO, Saving data for FFIV\n",
      "2025-01-30 20:07:06,509, data_manager.py, 83, INFO, Saving data for FI\n",
      "2025-01-30 20:07:07,092, data_manager.py, 83, INFO, Saving data for FICO\n",
      "2025-01-30 20:07:07,753, data_manager.py, 83, INFO, Saving data for FIS\n",
      "2025-01-30 20:07:08,422, data_manager.py, 83, INFO, Saving data for FITB\n",
      "2025-01-30 20:07:09,000, data_manager.py, 83, INFO, Saving data for FLT\n",
      "2025-01-30 20:07:09,534, data_manager.py, 83, INFO, Saving data for FMC\n",
      "2025-01-30 20:07:10,095, data_manager.py, 83, INFO, Saving data for FOX\n",
      "2025-01-30 20:07:10,648, data_manager.py, 83, INFO, Saving data for FOXA\n",
      "2025-01-30 20:07:11,404, data_manager.py, 83, INFO, Saving data for FRT\n",
      "2025-01-30 20:07:12,161, data_manager.py, 83, INFO, Saving data for FSLR\n",
      "2025-01-30 20:07:12,720, data_manager.py, 83, INFO, Saving data for FTNT\n",
      "2025-01-30 20:07:13,341, data_manager.py, 83, INFO, Saving data for FTV\n",
      "2025-01-30 20:07:13,898, data_manager.py, 83, INFO, Saving data for GD\n",
      "2025-01-30 20:07:14,481, data_manager.py, 83, INFO, Saving data for GE\n",
      "2025-01-30 20:07:15,179, data_manager.py, 83, INFO, Saving data for GEHC\n",
      "2025-01-30 20:07:15,819, data_manager.py, 83, INFO, Saving data for GEN\n",
      "2025-01-30 20:07:16,451, data_manager.py, 83, INFO, Saving data for GILD\n",
      "2025-01-30 20:07:17,046, data_manager.py, 83, INFO, Saving data for GIS\n",
      "2025-01-30 20:07:17,581, data_manager.py, 83, INFO, Saving data for GL\n",
      "2025-01-30 20:07:18,193, data_manager.py, 83, INFO, Saving data for GLW\n",
      "2025-01-30 20:07:18,773, data_manager.py, 83, INFO, Saving data for GM\n",
      "2025-01-30 20:07:19,330, data_manager.py, 83, INFO, Saving data for GNRC\n",
      "2025-01-30 20:07:19,949, data_manager.py, 83, INFO, Saving data for GOOG\n",
      "2025-01-30 20:07:20,524, data_manager.py, 83, INFO, Saving data for GOOGL\n",
      "2025-01-30 20:07:21,110, data_manager.py, 83, INFO, Saving data for GPC\n",
      "2025-01-30 20:07:21,657, data_manager.py, 83, INFO, Saving data for GPN\n",
      "2025-01-30 20:07:22,191, data_manager.py, 83, INFO, Saving data for GRMN\n",
      "2025-01-30 20:07:22,823, data_manager.py, 83, INFO, Saving data for GS\n",
      "2025-01-30 20:07:23,426, data_manager.py, 83, INFO, Saving data for GWW\n",
      "2025-01-30 20:07:24,008, data_manager.py, 83, INFO, Saving data for HAL\n",
      "2025-01-30 20:07:24,570, data_manager.py, 83, INFO, Saving data for HAS\n",
      "2025-01-30 20:07:25,120, data_manager.py, 83, INFO, Saving data for HBAN\n",
      "2025-01-30 20:07:25,648, data_manager.py, 83, INFO, Saving data for HCA\n",
      "2025-01-30 20:07:26,204, data_manager.py, 83, INFO, Saving data for HD\n",
      "2025-01-30 20:07:26,738, data_manager.py, 83, INFO, Saving data for HES\n",
      "2025-01-30 20:07:27,329, data_manager.py, 83, INFO, Saving data for HIG\n",
      "2025-01-30 20:07:27,880, data_manager.py, 83, INFO, Saving data for HII\n",
      "2025-01-30 20:07:28,419, data_manager.py, 83, INFO, Saving data for HLT\n",
      "2025-01-30 20:07:28,977, data_manager.py, 83, INFO, Saving data for HOLX\n",
      "2025-01-30 20:07:29,508, data_manager.py, 83, INFO, Saving data for HON\n",
      "2025-01-30 20:07:30,116, data_manager.py, 83, INFO, Saving data for HPE\n",
      "2025-01-30 20:07:30,684, data_manager.py, 83, INFO, Saving data for HPQ\n",
      "2025-01-30 20:07:31,356, data_manager.py, 83, INFO, Saving data for HRL\n",
      "2025-01-30 20:07:32,047, data_manager.py, 83, INFO, Saving data for HSIC\n",
      "2025-01-30 20:07:32,632, data_manager.py, 83, INFO, Saving data for HST\n",
      "2025-01-30 20:07:33,384, data_manager.py, 83, INFO, Saving data for HSY\n",
      "2025-01-30 20:07:34,076, data_manager.py, 83, INFO, Saving data for HUBB\n",
      "2025-01-30 20:07:34,607, data_manager.py, 83, INFO, Saving data for HUM\n",
      "2025-01-30 20:07:35,153, data_manager.py, 83, INFO, Saving data for HWM\n",
      "2025-01-30 20:07:35,676, data_manager.py, 83, INFO, Saving data for IBM\n",
      "2025-01-30 20:07:36,261, data_manager.py, 83, INFO, Saving data for ICE\n",
      "2025-01-30 20:07:36,817, data_manager.py, 83, INFO, Saving data for IDXX\n",
      "2025-01-30 20:07:37,440, data_manager.py, 83, INFO, Saving data for IEX\n",
      "2025-01-30 20:07:38,008, data_manager.py, 83, INFO, Saving data for IFF\n",
      "2025-01-30 20:07:38,567, data_manager.py, 83, INFO, Saving data for ILMN\n",
      "2025-01-30 20:07:39,173, data_manager.py, 83, INFO, Saving data for INCY\n",
      "2025-01-30 20:07:39,742, data_manager.py, 83, INFO, Saving data for INTC\n",
      "2025-01-30 20:07:40,313, data_manager.py, 83, INFO, Saving data for INTU\n",
      "2025-01-30 20:07:40,878, data_manager.py, 83, INFO, Saving data for INVH\n",
      "2025-01-30 20:07:41,425, data_manager.py, 83, INFO, Saving data for IP\n",
      "2025-01-30 20:07:42,030, data_manager.py, 83, INFO, Saving data for IPG\n",
      "2025-01-30 20:07:42,600, data_manager.py, 83, INFO, Saving data for IQV\n",
      "2025-01-30 20:07:43,213, data_manager.py, 83, INFO, Saving data for IR\n",
      "2025-01-30 20:07:43,822, data_manager.py, 83, INFO, Saving data for IRM\n",
      "2025-01-30 20:07:44,417, data_manager.py, 83, INFO, Saving data for ISRG\n",
      "2025-01-30 20:07:45,097, data_manager.py, 83, INFO, Saving data for IT\n",
      "2025-01-30 20:07:45,847, data_manager.py, 83, INFO, Saving data for ITW\n",
      "2025-01-30 20:07:46,581, data_manager.py, 83, INFO, Saving data for IVZ\n",
      "2025-01-30 20:07:47,282, data_manager.py, 83, INFO, Saving data for J\n",
      "2025-01-30 20:07:48,009, data_manager.py, 83, INFO, Saving data for JBHT\n",
      "2025-01-30 20:07:48,767, data_manager.py, 83, INFO, Saving data for JBL\n",
      "2025-01-30 20:07:49,393, data_manager.py, 83, INFO, Saving data for JCI\n",
      "2025-01-30 20:07:50,124, data_manager.py, 83, INFO, Saving data for JKHY\n",
      "2025-01-30 20:07:50,831, data_manager.py, 83, INFO, Saving data for JNJ\n",
      "2025-01-30 20:07:51,481, data_manager.py, 83, INFO, Saving data for JNPR\n",
      "2025-01-30 20:07:52,133, data_manager.py, 83, INFO, Saving data for JPM\n",
      "2025-01-30 20:07:52,768, data_manager.py, 83, INFO, Saving data for K\n",
      "2025-01-30 20:07:53,338, data_manager.py, 83, INFO, Saving data for KDP\n",
      "2025-01-30 20:07:53,956, data_manager.py, 83, INFO, Saving data for KEY\n",
      "2025-01-30 20:07:54,542, data_manager.py, 83, INFO, Saving data for KEYS\n",
      "2025-01-30 20:07:55,171, data_manager.py, 83, INFO, Saving data for KHC\n",
      "2025-01-30 20:07:55,767, data_manager.py, 83, INFO, Saving data for KIM\n",
      "2025-01-30 20:07:56,369, data_manager.py, 83, INFO, Saving data for KLAC\n",
      "2025-01-30 20:07:56,934, data_manager.py, 83, INFO, Saving data for KMB\n",
      "2025-01-30 20:07:57,502, data_manager.py, 83, INFO, Saving data for KMI\n",
      "2025-01-30 20:07:58,036, data_manager.py, 83, INFO, Saving data for KMX\n",
      "2025-01-30 20:07:58,603, data_manager.py, 83, INFO, Saving data for KO\n",
      "2025-01-30 20:07:59,154, data_manager.py, 83, INFO, Saving data for KR\n",
      "2025-01-30 20:07:59,697, data_manager.py, 83, INFO, Saving data for KVUE\n",
      "2025-01-30 20:08:00,269, data_manager.py, 83, INFO, Saving data for L\n",
      "2025-01-30 20:08:00,830, data_manager.py, 83, INFO, Saving data for LDOS\n",
      "2025-01-30 20:08:01,384, data_manager.py, 83, INFO, Saving data for LEN\n",
      "2025-01-30 20:08:02,011, data_manager.py, 83, INFO, Saving data for LH\n",
      "2025-01-30 20:08:02,564, data_manager.py, 83, INFO, Saving data for LHX\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jcp_2\\production\\01_materials\\labs\\../../05_src\\data_manager.py:44\u001b[0m, in \u001b[0;36mDataManager.download_all\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m _logs\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGetting price data for all tickers.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_tickers()\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_all_tickers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jcp_2\\production\\01_materials\\labs\\../../05_src\\data_manager.py:59\u001b[0m, in \u001b[0;36mDataManager.process_all_tickers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     57\u001b[0m _logs\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing all tickers\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     58\u001b[0m ticker_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtickers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_and_save_by_year\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprice_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jcp_2\\production\\01_materials\\labs\\../../05_src\\data_manager.py:73\u001b[0m, in \u001b[0;36mDataManager.get_data_and_save_by_year\u001b[1;34m(tickers, start_date, end_date, outpath, sector, subsector)\u001b[0m\n\u001b[0;32m     71\u001b[0m ticker_dt \u001b[38;5;241m=\u001b[39m DataManager\u001b[38;5;241m.\u001b[39mget_stock_price_data(tickers, start_date, end_date)\n\u001b[0;32m     72\u001b[0m _logs\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticker_dt columns \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker_dt\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 73\u001b[0m \u001b[43mDataManager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_by_year\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker_dt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jcp_2\\production\\01_materials\\labs\\../../05_src\\data_manager.py:91\u001b[0m, in \u001b[0;36mDataManager.save_by_year\u001b[1;34m(ticker_dt, outpath)\u001b[0m\n\u001b[0;32m     87\u001b[0m yr_dd \u001b[38;5;241m=\u001b[39m (dd\n\u001b[0;32m     88\u001b[0m          \u001b[38;5;241m.\u001b[39mfrom_pandas(t_dt[t_dt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m yr], npartitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     89\u001b[0m          \u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     90\u001b[0m yr_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(outpath, ticker, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 91\u001b[0m \u001b[43myr_dd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43myr_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jcp_2\\anaconda3\\envs\\dsi_participant\\lib\\site-packages\\dask_expr\\_collection.py:3296\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[1;34m(self, path, **kwargs)\u001b[0m\n\u001b[0;32m   3293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_parquet\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   3294\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask_expr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[1;32m-> 3296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m to_parquet(\u001b[38;5;28mself\u001b[39m, path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jcp_2\\anaconda3\\envs\\dsi_participant\\lib\\site-packages\\dask_expr\\io\\parquet.py:593\u001b[0m, in \u001b[0;36mto_parquet\u001b[1;34m(df, path, compression, write_index, append, overwrite, ignore_divisions, partition_on, storage_options, custom_metadata, write_metadata_file, compute, compute_kwargs, schema, name_function, filesystem, engine, **kwargs)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-defined key/value metadata (custom_metadata) can not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    586\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontain a b\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m key.  This key is reserved by Pandas, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    587\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand overwriting the corresponding value can render the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    588\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentire dataset unreadable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    589\u001b[0m     )\n\u001b[0;32m    591\u001b[0m \u001b[38;5;66;03m# Engine-specific initialization steps to write the dataset.\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;66;03m# Possibly create parquet metadata, and load existing stuff if appending\u001b[39;00m\n\u001b[1;32m--> 593\u001b[0m i_offset, fmd, metadata_file_exists, extra_write_kwargs \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39minitialize_write(\n\u001b[0;32m    594\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_legacy_dataframe(),\n\u001b[0;32m    595\u001b[0m     fs,\n\u001b[0;32m    596\u001b[0m     path,\n\u001b[0;32m    597\u001b[0m     append\u001b[38;5;241m=\u001b[39mappend,\n\u001b[0;32m    598\u001b[0m     ignore_divisions\u001b[38;5;241m=\u001b[39mignore_divisions,\n\u001b[0;32m    599\u001b[0m     partition_on\u001b[38;5;241m=\u001b[39mpartition_on,\n\u001b[0;32m    600\u001b[0m     division_info\u001b[38;5;241m=\u001b[39mdivision_info,\n\u001b[0;32m    601\u001b[0m     index_cols\u001b[38;5;241m=\u001b[39mindex_cols,\n\u001b[0;32m    602\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m    603\u001b[0m     custom_metadata\u001b[38;5;241m=\u001b[39mcustom_metadata,\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    605\u001b[0m )\n\u001b[0;32m    607\u001b[0m \u001b[38;5;66;03m# By default we only write a metadata file when appending if one already\u001b[39;00m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;66;03m# exists\u001b[39;00m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m append \u001b[38;5;129;01mand\u001b[39;00m write_metadata_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jcp_2\\anaconda3\\envs\\dsi_participant\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\arrow.py:740\u001b[0m, in \u001b[0;36mArrowDatasetEngine.initialize_write\u001b[1;34m(cls, df, fs, path, append, partition_on, ignore_divisions, division_info, schema, index_cols, **kwargs)\u001b[0m\n\u001b[0;32m    737\u001b[0m     schema \u001b[38;5;241m=\u001b[39m inferred_schema\n\u001b[0;32m    739\u001b[0m \u001b[38;5;66;03m# Check that target directory exists\u001b[39;00m\n\u001b[1;32m--> 740\u001b[0m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m append \u001b[38;5;129;01mand\u001b[39;00m division_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    742\u001b[0m     ignore_divisions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jcp_2\\anaconda3\\envs\\dsi_participant\\lib\\site-packages\\fsspec\\spec.py:1510\u001b[0m, in \u001b[0;36mAbstractFileSystem.mkdirs\u001b[1;34m(self, path, exist_ok)\u001b[0m\n\u001b[0;32m   1508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmkdirs\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1509\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Alias of `AbstractFileSystem.makedirs`.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jcp_2\\anaconda3\\envs\\dsi_participant\\lib\\site-packages\\fsspec\\implementations\\local.py:54\u001b[0m, in \u001b[0;36mLocalFileSystem.makedirs\u001b[1;34m(self, path, exist_ok)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmakedirs\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     53\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strip_protocol(path)\n\u001b[1;32m---> 54\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jcp_2\\anaconda3\\envs\\dsi_participant\\lib\\os.py:213\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tail:\n\u001b[0;32m    212\u001b[0m     head, tail \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39msplit(head)\n\u001b[1;32m--> 213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m         makedirs(head, exist_ok\u001b[38;5;241m=\u001b[39mexist_ok)\n",
      "File \u001b[1;32mc:\\Users\\jcp_2\\anaconda3\\envs\\dsi_participant\\lib\\genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dm.download_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, add features to the data set and save to a *feature store*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 20:08:09,647, data_manager.py, 114, INFO, Creating features data.\n",
      "2025-01-30 20:08:09,649, data_manager.py, 124, INFO, Loading price data from ../../05_src/data/prices/\n",
      "2025-01-30 20:08:11,762, data_manager.py, 133, INFO, Creating features\n",
      "c:\\Users\\jcp_2\\production\\01_materials\\labs\\../../05_src\\data_manager.py:136: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  features = (price_dd.groupby('Ticker', group_keys=False)\n",
      "2025-01-30 20:08:11,769, data_manager.py, 158, INFO, Saving features to ../../05_src/data/features/stock_features.parquet\n"
     ]
    }
   ],
   "source": [
    "dm.featurize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
